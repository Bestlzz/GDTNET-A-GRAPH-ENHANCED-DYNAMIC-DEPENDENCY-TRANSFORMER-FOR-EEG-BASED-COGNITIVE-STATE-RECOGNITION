The proposed framework integrates temporal encoding, graph-based connectivity modeling, dynamic dependency aggregation, and global attention mechanisms into a unified architecture for EEG-based cognitive state classification. The pipeline of the GDTNet is illustrated in Fig.1.
First, each EEG segment is processed by the GraphPLV Encoder, which combines temporal convolutional representations with PLV-guided graph convolution to extract segment-level embeddings that capture both intra-channel dynamics and inter-channel synchronization. Next, the Dynamic De-
pendency Integration (DDI) module refines these embeddings by performing autoregressive local temporal aggregation, thereby enhancing short-range dependencies among adjacent EEG segments. Finally, the Transformer-based classifier introduces a learnable [CLS] token and applies multi-head self-attention to model long-range dependencies across all segments, producing a compact global representation for downstream classification.
